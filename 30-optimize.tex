\chapter{目标代码优化}

\label{chap:optimize}
在上一章中，我们生成了一串可执行的 asm 指令，但 CPU 在实际运行它时，所执行的指令数量较大，从而导致执行性能变差。
本章我们将通过一些操作来减少 CPU 实际运行时所执行的指令数量，从而提高程序的执行效率。

\begin{remark}
本章的参考资料有：
\begin{itemize}
    \item 现代编译原理：C 语言描述\cite{TigerBook}
    \item 编译原理\cite{DragonBook}
    \item \textit{Engineering a Compiler}\cite{EngineeringACompiler}
    \item SSA Construction \& Destruction\cite{SSAConstructionAndDestruction}
\end{itemize}
\end{remark}

\section{什么是优化？}

比较以下两串等价的 asm 代码：
\begin{lstlisting}
    addi rd, rs1, 1
    addi rd, rs1, 2
\end{lstlisting}
\begin{lstlisting}  
    addi rd, rs1, 3
\end{lstlisting}

两串代码实现了同样的功能。第一串代码使用了2条指令，第二串代码只用了1条指令。
我们的「优化」指的就是在不影响运行结果（输出）的前提下，尽可能把指令数量减少。
例如像上文中把第一串代码优化成第二串代码的过程，就是一种优化。

当然，存在非常简单的优化，例如你可以把诸如 \texttt{addi x0, x0, 0} 这样的指令删除，
但这样的优化，在效果上的泛化性是不够的。
本章节将为大家介绍一些更加复杂的优化方法，如寄存器分配、Mem2Reg 等。

\section{基本块划分}

我们日常写的程序通常有着较为复杂的逻辑，包括分支、循环等结构。
如果我们以一条指令为单位，控制流将变得非常复杂，因此我们提出\textbf{基本块 (Basic Block)} 的概念。
一个基本块由前驱、后继和一串顺序执行的指令（即这串指令中不存在任何跳转指令）组成。
所有的跳转逻辑，通过维护基本块之间的前驱、后继关系来保证。
通过基本块的划分，目标程序自然地被表示成一张有向图，图的节点就是这些基本块，边表示了他们之间的跳转关系。
上面提到的由以基本块为节点的有向图，被称作\textbf{控制流图 (Control Flow Graph, CFG)}。
下面提到的活跃分析，将在控制流图的基础上进行。

\section{活跃分析}

活跃分析可以告诉我们一个函数中的变量在程序执行过程中是否处于活跃状态。
处于活跃状态的变量在程序执行过程中，其值可能被使用。反之，不活跃的变量在程序执行过程中，其值不会被使用。

粗略地，我们有这样的想法：在同一时间戳活跃的变量不应该占用同一个寄存器，否则会导致数据冲突。
就此我们能够构建出冲突图，从而进行寄存器分配。这个我们留到后面讲。

\subsection{概念}

以下是活跃分析中的一些概念定义：

\begin{description}
    \item[def 和 use:]def 是在一条指令中被赋值，即被定义的变量；use 指在这条指令中被使用的变量。
例如：在以下语句中，\texttt{a} 是 def，\texttt{b} 和 \texttt{c} 是 use。
\begin{lstlisting}[language=c]
    a = b + c
\end{lstlisting}

首先为了简单起见，我们先假设每个基本块只包含一条指令。后面我们会介绍包含多条指令的基本块的等效 use 和 def。

\item[活跃:] 表示这个变量的值将来还要继续使用。一个变量在一条边上活跃，
  指存在一条从这条边通向它的一个 use 且不经过任何它的 def 的有向路径（即保持当前的值直到被下一次使用）。

\item[入口活跃:] 一个变量在一个块中是入口活跃的，当且仅当这个变量在当前块节点的任意一条入边是活跃的。
  注意，根据活跃的定义，这等价于这个变量在当前块节点的所有入边都是活跃的。

\item[出口活跃:] 一个变量在一个块中是出口活跃的，当且仅当这个变量在当前块节点的任意一条出边是活跃的。

\end{description}

\subsection{活跃分析的算法}

变量（当然你可以称之为虚拟寄存器）在每个块中的活跃状态可由它们的 def 和 use 算出。对每个节点 $n$ 都有：
（下文中 $\mathit{suc}$ 表示后继节点的集合）
\begin{align*}
\mathit{in}[n]  &= \mathit{use}[n] \cup (\mathit{out}[n] - \mathit{def}[n]), \\
\mathit{out}[n] &= \bigcup_{s \in \mathit{suc}[n]} \mathit{in}[s].
\end{align*}
当然，还有边界条件：
$$
\mathit{out}[\mathit{exit}] = \emptyset
$$
上面的式子被称为\textbf{活跃分析的数据流方程}。

\begin{itemize}
\item $\mathit{use}[n]$ 一定都属于 $\mathit{in}[n]$，因为这些 use 在当前块的所有入边都活跃。

\item 对于 $\mathit{out}[n]$ 中的变量，如果它在这个块中没有被 def 过，则它一定在 $\mathit{in}[n]$ 中。
这是因为如果此节点的一条出边是活跃的，则它一定通过这条出边指向了一个它的 use 且不经过任何 def。
那么在这条路径前面再任意加一条当前块的入边，它仍然是一个指向该变量的 use 且不经过任何
def（这个块中没有 def），那么这条入边肯定也是活跃的。

\item 如果一个变量在当前块的某个后继中是入口活跃的，则它在当前块中一定是出口活跃的。
因为它在当前块的该后继的所有入边都活跃，则在当前块连着这个后继的那条边上，它一定是活跃的。

\item 边界条件：所有变量在函数结束时都消亡了。
\end{itemize}

具体地，我们的算法可以通过不动点迭代的方式进行。一般来说，是从出口开始倒序地 BFS 遍历控制流图，
因为出口处的边界条件是确定的。
对所有的基本块都可以进行如上的迭代，直到收敛（一次完整迭代前后没有变动）为止。

\subsection{基本块的等效 use/def}

前面假设了一个基本块只包含一条指令。现在我们从活跃分析的流方程出发，来推导包含多条指令的基本块的等效 use/def。

包含多条指令的基本块可以视为由两个更小的基本块合并而成。
因此，我们只考虑两个基本块的合并。设这两个基本块为 $p \to n$，
$p$ 只有一个后继 $n$，$n$ 只有一个前驱 $p$。记合并后的基本块为 $pn$。
于是我们有 $\mathit{out}[p] = \mathit{in}[n]$。进而有：
\begin{align*}
  \mathit{in}[pn] &= \mathit{in}[p] = \mathit{use}[p] \cup (\mathit{out}[p] - \mathit{def}[p]) \\
  &= \mathit{use}[p] \cup (\mathit{in}[n] - \mathit{def}[p]) \\
  &= \mathit{use}[p] \cup \left(\mathit{use}[n] \cup (\mathit{out}[n] - \mathit{def}[n]) - \mathit{def}[p]\right) \\
  &= \mathit{use}[p] \cup (\mathit{use}[n] - \mathit{def}[p]) \cup (\mathit{out}[n] - \mathit{def}[n] - \mathit{def}[p]) \\
  &= \left(\mathit{use}[p] \cup (\mathit{use}[n] - \mathit{def}[p])\right) \cup \left(\mathit{out}[pn]
   - (\mathit{def}[n] \cup \mathit{def}[p])\right).
\end{align*}

所以我们可以把 $\mathit{use}[p] \cup (\mathit{use}[n] - \mathit{def}[p])$ 视为 $pn$ 的等效 use，
把 $\mathit{def}[n] \cup \mathit{def}[p]$ 视为 $pn$ 的等效 def。

以基本块为单位进行迭代法，可以提高算法的效率。因为如果不合并，那每次迭代过程中基本块内部的 in/out 都会再算一遍。
另一方面，得到基本块的等效 in/out 后，我们很容易根据流方程得到内部每条指令的 in/out。

\section{Mem2Reg 优化}\label{mem2reg}

如果你使用标准 LLVM IR 作为中间代码表示，那么其一个优化是 Mem2Reg。
顾名思义，它就是把一个本来要被多次反复 load 和 store 的临时变量改用寄存器（如果分配算法允许的话）来存。

LLVM有一个假设：程序中所有的局部变量都在栈上，并且通过 \texttt{alloca} 指令在函数的 entry block
进行声明，并且这些声明只出现在 entry block中。
对于这些 \texttt{alloca}，LLVM 会做检查，如果一个 \texttt{alloca} 出来的临时变量只有
load 和 store 作为 use，那么它就是可以被转成静态单赋值形式 (Static Single Assignment，SSA) 而被消除的。
由于 Mx* 语言没有取地址之类的指令，所以所有的 \texttt{alloca} 指令理论上都可以被消除。

把 \texttt{alloca} 交由编译器后端来处理是很复杂的。所以我们需要将它们转换成 SSA 形式。
简单地说，我们需要通过插入 \texttt{phi} 函数的形式来表示变量在从不同分支而来的块中被赋值，这样就可以消除
\texttt{alloca} 了。
而如何正确插入 \texttt{phi}函数，我们需要在支配树上做分析，最后再根据我们放置的
\texttt{phi} 函数来重写 \texttt{load} 与 \texttt{store} 指令。

总的来说，将 IR 转化成 SSA 形式，我们就容易在支配树上做支配关系的分析，从而确定一些与控制流无关的数据流。

\subsection{静态单赋值形式 (SSA) 与 \texttt{phi} 指令}

静态单赋值形式 (Single Static Assignment)，顾名思义即每个变量只被赋值一次。
对于多次赋值，我们用变量的不同 “版本” 来控制。例如：
\begin{lstlisting}[language=LLVM]
    %x = add i32 1, 2
    %x = add i32 %x, 3
    %x = add i32 %x, 4
\end{lstlisting}

转化为SSA形式后：
\begin{lstlisting}[language=LLVM]
    %x.0 = add i32 1, 2
    %x.1 = add i32 %x.0, 3
    %x.2 = add i32 %x.1, 4
\end{lstlisting}

注意 \texttt{x.0}, \texttt{x.1} ,\texttt{x.2} 都是不同的变量。

SSA 形式通过插入 \texttt{phi} 指令来处理控制流分支的问题。
\texttt{phi} 指令用于合并不同控制流路径上的变量版本，以确保变量在不同路径上的使用是一致的。
在 LLVM IR 中，\texttt{phi} 指令通常以这样的格式写出：
\begin{lstlisting}[language=LLVM]
    %x.0 = phi <type> [ <val1>, <block1> ], [ <val2>, <block2> ], [ <val3>, <block3> ]
\end{lstlisting}

这代表着，变量 \texttt{x.0} 将被赋值 \texttt{val1}（如果控制流通过了 \texttt{block1}
所在的分支而来），或 \texttt{val2}（控制流通过了 \texttt{block2}
所在的分支而来）或 \texttt{val3}（控制流通过了 \texttt{block3} 所在的分支而来）。

从具体效果上看，可以看下面这个例子：
\begin{lstlisting}[language=C]
// 这是一段简单的 C 代码
int main(){
    int x = 2, y = 3;
    int b;
    if(x + 1 > y) {
        b = -1;
    } else {
        b = 1;
    }
    return b;
}
\end{lstlisting}

下面是它生成的 IR：

\begin{lstlisting}[language=LLVM]
; 不带优化的 LLVM IR
define dso_local i32 @main() #0 {
entry:
  %retval = alloca i32, align 4
  %x = alloca i32, align 4
  %y = alloca i32, align 4
  %b = alloca i32, align 4
  store i32 0, i32* %retval, align 4
  store i32 2, i32* %x, align 4
  store i32 3, i32* %y, align 4
  %0 = load i32, i32* %x, align 4
  %add = add nsw i32 %0, 1
  %1 = load i32, i32* %y, align 4
  %cmp = icmp sgt i32 %add, %1
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  store i32 -1, i32* %b, align 4
  br label %if.end

if.else:                                          ; preds = %entry
  store i32 1, i32* %b, align 4
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  %2 = load i32, i32* %b, align 4
  ret i32 %2
}

; 带 Mem2Reg 优化的 LLVM IR
define dso_local i32 @main() #0 {
entry:
  %add = add nsw i32 2, 1
  %cmp = icmp sgt i32 %add, 3
  br i1 %cmp, label %if.then, label %if.else

if.then:                                          ; preds = %entry
  br label %if.end

if.else:                                          ; preds = %entry
  br label %if.end
    
if.end:                                           ; preds = %if.else, %if.then
  %b.0 = phi i32 [ -1, %if.then ], [ 1, %if.else ]
  ret i32 %b.0
}
\end{lstlisting}
可以看到 Mem2Reg 优化过后，代码干净了很多。注意到最后一个基本块开头的 \texttt{phi} 指令。
而如何正确地插入 \texttt{phi} 指令，我们需要通过构建支配树来分析。

\subsection{支配树与 \texttt{phi} 指令的放置}

关于支配树我们需要引入一些概念：

\begin{description}
    \item[支配 (Dominate)]
    如果每一条从流图的入口结点到结点 $n$ 的路径都经过结点 $d$, 我们就说 $d$ 支配 $n$，记为 $d$ dom $n$。
    请注意，在这个定义下每个结点都支配它自己。
    \item[支配集]
    结点 $n$ 的支配集合是所有支配 $n$ 的结点的集合，记为 $\mathit{Dom}(n)$。
    \item[严格支配 (Strictly Dominate)]
    $n$ 严格支配 $d$ 当且仅当 $d$ 支配 $n$ 且 $n\neq d$, 记作 $d$ sdom $n$。
       
    \item[支配树 (Dominator Tree)]
    通过节点之间的支配关系，我们就可以依此来建立一颗支配树。在支配树中，节点 a 到 b 连边当且仅当 a 严格支配 b。

    \item[直接支配节点 (Intermediate Dominator， IDom)]
    在支配树中，对于结点 n 来说，从根节点到结点 n 所在路径上的节点（不包括）都严格支配节点 n，
    我们把在该路径上距离 n 最近的支配 n 的节点称作节点 n 的。
    \item[支配边界 (Dominance Frontier)]
    Y 是 X 的支配边界，当且仅当 X 支配 Y 的一个前驱结点（在 CFG 中）
    同时 X 并不严格支配 Y。
\end{description}

我们说，在 SSA 形式下，一个 def 一定支配它的 use。因为是 SSA，所以一个变量只会被赋值一次，即只会有一次 def。
那么从程序上说我们要 use 一个变量，这个变量必然需要先被 def。根据支配的定义，入口到每一个
use 的路径都必然经过这一个 def，即这个 def 支配了所有的 use。

由于每个 def 支配对应的 use，所以如果达到了 def 所在 block 的支配边界，
就必须考虑其他路径是否有其他表示着相同变量的不同版本的定义，
由于在编译期间无法确定会采用哪一条分支，所以需要放置 \texttt{phi} 指令。

\subsubsection{支配树构建算法}

构建支配树并计算支配关系的算法有很多，这里介绍一种性能相对一般的算法，你可以考虑实现其他算法如 Lengauer-Tarjan
算法。

首先我们有：$\mathit{Dom}(n) = \{n\} \bigcup \left(\bigcap_{m\in \mathit{preds}(n)} \mathit{Dom}(m)\right)$。
即：一个节点的支配集等于其所有前驱节点支配集的共同前缀再并上自身。
这是显而易见的，因为节点 a 支配 b 就意味着 a 支配 b 的所有前驱节点。

我们可以通过对每个节点的迭代来计算支配集，即先假设所有节点的支配集都是节点全集，然后不断迭代直到收敛。
具体地，你可以在迭代的每一步都运行一遍 $\mathit{Dom}(n) \leftarrow \{n\} \bigcup
\left(\bigcap_{m\in \mathit{preds}(n)} \mathit{Dom}(m)\right)$,
直到一遍下来所有 $\mathit{Dom}(n)$ 不发生变化为止。
由于控制流图是前向传播的，所以这里迭代的顺序一般采用 RPO (Reverse Post Order)。

这样我们就获得了所有的 $\mathit{Dom}(n)$, 也就是获得了所有节点的支配关系。

\subsubsection{\texttt{phi} 指令放置算法}

假设我们现在获得了支配树以及所有节点的支配关系，即我们知道了每个节点的 Dominance Frontier。
比较朴素的一个想法是：先收集所有被定义过的变量名；再对每个变量名，遍历所有指令找到所有 \texttt{AllocaNode}
以及被 \texttt{alloca} 出来的变量的 def，获得这些 def 所在的块的支配边界，
并在支配边界的块头部插入 \texttt{phi} 指令。
对于多个对相同变量的 \texttt{phi} 指令，我们应当合并 \texttt{phi} 指令。

\texttt{phi} 函数放置完毕后，我们需要对变量的使用进行重命名，即维护好之前提到的变量的 “版本”。
一种可行的方式是：我们可以对每个变量名开一个栈。

在每个基本块中，算法首先重命名 entry block 顶部的 \texttt{phi} 指令所定义的值，
然后按序访问程序块中的各个指令。算法会用当前的 SSA 形式名（栈顶）重写各个操作数，
并为操作的结果创建一个新的 SSA 形式名（入栈）。

算法的后一步使得新名字成为当前的名字（入栈了之后就在栈顶）。在基本块中所有的操作都已经重写之后，
我们将使用当前的 SSA 形式名重写程序块在 CFG 中各后继结点中的适当 \texttt{phi} 指令的参数。

最后，对当前基本块在支配树中的子结点进行递归处理，这是一个在 CFG 上 DFS 的过程。
当算法从这些递归调用返回时，它会将当前 SSA 形式变量名的集合恢复到访问当前块之前的状态（出栈）。

\subsection{静态单赋值形式 (SSA) 的消除} \label{SSA-eliminate-phi}

经过 mem2reg，我们生成了很多 \texttt{phi}。然而，汇编中没有 \texttt{phi} 指令的直接对应，所以我们须将其消除，
用等价的其余指令如 \texttt{move} 来代替。一般地，我们在拥有 \texttt{phi} 指令的这个块的前驱块中插入一份拷贝，
例如：（BB 表示 \textbf{B}asic \textbf{B}lock）
\begin{lstlisting}
        BB1
        x1 = 0
        /    \
    BB2      BB3
    x2 = 1   x3 = 2
      \    /
         BB4
         x4 = phi[(x2,BB2), (x3,BB3)]
\end{lstlisting}

我们就将 \texttt{x4} 的拷贝插入 BB2 和 BB3 中，得到：
\begin{lstlisting}
        BB1
        x1 = 0
        /     \
    BB2        BB3
    x2 = 1     x3 = 2
    x4 = x2    x4 = x3
    \       /
           BB4
         ...
\end{lstlisting}

这样的操作能解决大部分的 \texttt{phi} 指令，但是还有一些特殊情况需要处理，例如：
\begin{lstlisting}
      BB1      BB4
      /  \    /
    BB2   BB3
\end{lstlisting}

我们看到BB1有两个后继，BB3 有两个前驱。假设 BB2、BB3 都有 \texttt{phi} 指令，则它们都会往
BB1 插入拷贝，这就会导致该变量在 BB1 上被修改，从而影响到 BB2 所在的分支进而引起数据冲突。
我们发现，BB1-BB3 之间的这条 edge 有这样的特点：出端有多个后继且入端有多个前驱。我们称这样的
edge 为 \textbf{critical edge}。

所有的 critical edge 都可能会引起上述的数据冲突。
为了解决 critical edge，我们需要在 critical edge 中间插入一个新的空基本块，即：
\begin{lstlisting}
    BB1    
    /  \       
  BB2   BB5  BB4
        \    /   
            BB3     
\end{lstlisting}

BB5 是我们新插入的块。这样一来，我们就把 critical edge 给消除了。
BB3 中的 \texttt{phi} 指令会往 BB5 和 BB4 中插入拷贝，而 BB2 中的 \texttt{phi} 指令会往
BB1 中插入拷贝，这样就不会有数据冲突了。

\section{寄存器分配：冲突图与图染色算法}

寄存器分配的目标有二：
\begin{itemize}
    \item 尽可能地将变量（尤其是临时变量）分配到寄存器中，而不是内存中。
    \item 尽量为 \texttt{move} 指令的 source 和 destination 分配同一个寄存器。
\end{itemize}

做完活跃分析之后，理论上我们可以通过判断两个变量是否同时活跃来知道哪些变量是存在 “冲突”
的，即他们不可共享同个寄存器。

冲突图 (Interference Graph) 就是表示变量之间冲突关系的图，它是一个无向图，图中的每个节点表示一个变量，
如果两个变量之间存在冲突，则它们之间有一条边。

但是寄存器的数量是有限的（以 K 个为例，下同），所以我们需要一个算法来对冲突图进行染色，
即将图中的每个节点（变量）染上颜色（分配到寄存器中）。当然大多数情况下，这张图是不能用 K 种颜色染色的，
则我们希望将尽量少的变量存到内存（栈）中然后再对剩下的图进行染色。把变量存在栈上，
就意味着它不需要使用任何寄存器资源，即我们可以将它从这张图中删除。这个过程被称为\textbf{溢出 (spill)}。

\subsection{建图 (Build)}

我们需要先构建冲突图。最基础的冲突关系是两个变量同时活跃。

之前我们维护的是基本块的活跃信息，现在我们需要推出所有指令的 \texttt{liveIn} 和 \texttt{liveOut}。
在一个基本块中，指令一定是顺序的（只有一个前驱和一个后继），
由于后面连边我们只用到 \texttt{liveOut}，所以这里就只求 \texttt{liveOut}。
最后一个指令的 \texttt{liveOut} 就是 block 的 \texttt{liveOut}。
然后前一个指令的 \texttt{liveOut} 是这一个基础上扣掉 def，加上 use。

对于冲突图的连边，我们顺序遍历块中指令，所有 def（代表一段生命周期的开始）向此时存活的其它变量连边，
表示它的生命周期的左端点被其他存活的变量的生命周期覆盖到了。
此时存活的变量包括这时刻的所有 def（同时开始活跃）和 \texttt{liveOut}（活跃到现在）。

\subsection{简化 (Simplify)}

注意到，判断一个图是否能被 K-染色是一个NP问题。对于一张图，假设我们现在想用 K 种颜色来染色，
则对于图中所有度数小于 K 的节点，无论其余的点采取何种染色方案，它都可以找到至少一种颜色可以染。那么我们可以先不染这种点。
也就是说，我们把这样的点以及其连着的边从冲突图上去掉，
然后染好剩下的图，再逆向地按照删点顺序把这些点染上颜色，就能构造出一种染色方案。
具体地，我们可以把这样的节点丢进一个栈 \texttt{selectStack} 代表我们选择了这些节点将要在染色阶段进行这一轮的染色。

下面会提到，传送有关 (move related) 的节点具有合并的可能性，故而在这一步，我们不对其进行简化。
一个节点是传送有关的当且仅当它是 \texttt{move} 指令的一个操作数（src 或 dest），否则它是传送无关的。简化过程只处理传送无关的节点。

而在简化过程中某一时刻，这张图可能只包含度数大于等于 K 的节点和传送有关的节点，这时我们的简化算法就无法继续进行了。
这时我们需要选择一个节点进行溢出，但我们对这个节点的溢出做出乐观的估计，即我们希望这个节点在最后是可以被染色的。
因此我们把这个被选中的节点删除并压入 \texttt{selectStack} 中，继续我们的简化处理。

\subsection{合并 (Coalesce)}

两个变量可以（在冲突图上）合并当且仅当它们之间无边并且它们由一个 \texttt{move} 指令相连（src 和 dest）。通过对冲突图的分析，我们很容易能减少冗余的传送指令。
合并指的是两个节点合并成一个节点，其邻节点为这两个节点原来邻居节点的并。
容易想到，合并这一过程，我们可以用并查集来进行维护。
但要注意的是，并不是只要符合定义都可以直接合并，因为合并完之后图可能从可 K-着色的变为不可K-着色的（从而造成溢出，这样并不优）。
具体地，合并时可以参考这两条规则：
\begin{itemize}
    \item Briggs 规则：合并后产生的节点所拥有的高度数（大于等于K）邻节点个数小于 K。因为简化会将这个合并后的节点移走。
    \item George 规则：a 和 b 可以合并的条件是：a 的每一个邻居 t，t 是低度数的或者 t 与 b 冲突。
    因为一次简化后，a 的所有邻居都和 b 相邻。
\end{itemize}

你可以在两条规则都满足的前提下才进行合并，当然你也可以只满足其中一条，或者加入一些对节点的特判，等等。
但这两条规则都是安全的，即当通过任意一条规则合并成功时，这张图不会从可 K-着色的变成不可 K-着色的。
当合并发生之后，新产生的节点将不再是传送有关的节点，因此我们可以将其放入待简化的工作表中,使得简化过程能进一步进行下去。

\subsection{冻结 (Freeze)}

前面提到合并有条件。在建图后维护所有工作表的时候，传送有关的节点因为有合并的希望暂时不放入待简化的工作表中。
如果传送与合并都无法进行，我们选择一个低度数的传送有关的节点，冻结与其有关的所有传送，即放弃这些传送的合并，使得其在下一轮被简化。

\subsection{选择溢出变量 (Select Spill)}

选择 \texttt{spillWorklist} 中的一个高度数节点进行溢出。
至于如何选择这一节点，你有很多种估价方式, 比如选择度数最大的，或者选择活跃区间最长的，
或者选择度数和活跃区间长度的乘积最大的，等等。
\texttt{spillWorklist}是被筛选出来的度数大于 K 的节点的集合。
溢出的节点，我们扔进另一个栈 \texttt{spilledStack} 中，等待分配栈空间给这些变量。

溢出的节点加入简化工作表等待被删除（虽然它并非低度数节点），等到染色时会区分可染色节点和溢出节点。

\subsection{进行染色 (Assign Color)}

对 \texttt{selectStack} （本轮需要染色的节点）里的点进行染色。
我们从一个空的图开始，通过重复地将栈顶节点添加到图中来重建冲突图。
根据简化阶段的性质，我们可以保证每次添加的节点都会有一种它能使用的颜色。
如果颜色不够，把当前节点放到已溢出表 \texttt{spilledStack} 中。

\subsection{相关代码重写 (Rewrite)}

如果存在溢出，我们需要逐个为其分配存储单元（一般来说是分配栈上的空间）。
然后给这些变量插入对应的 load 和 store。def 后插 store，use 前插 load。
我们就把这一溢出的变量变成了许多新创建的小临时变量（生命周期短），
因此我们需要对改变后的图重新调用一次整个过程。

整一个图染色寄存器分配过程的代码框架如下：
\begin{lstlisting}[language=java]
    public static void graphColoring(){
    LivenessAnalysis();    
    build();
    MakeWorklist();
        while(true){
           do {
                if (!simplifyWorklist.isEmpty()) simplify();
                else if (!movesWorklist.isEmpty()) coalesce();
                else if (!freezeWorklist.isEmpty()) freeze();
                else if (!spillWorklist.isEmpty()) selectSpill();
                } while (!simplifyWorklist.isEmpty() ||
                        !worklistMoves.isEmpty() ||
                        !freezeWorklist.isEmpty() ||
                        !spillWorklist.isEmpty());
        }
        assignColor();
        if(spilledStack.empty) return;
        rewrite();
        graphColoring();
    }
\end{lstlisting}

其中\texttt{MakeWorklist()}函数是初始化所有工作表。

\subsection{预着色节点的处理}

有一些临时变量需要被放在给定的寄存器上，比如函数的参数、返回地址等等，这些变量不能随意地分配颜色。
我们称这些变量是\textbf{预着色 (precolored)} 的。
在建图的时候，我们需要把这些变量加入冲突图，但是不能把它们加入工作表中，即它们不能被简化，更不可能被溢出。

因此我们可以默认这些节点的度数为无穷大，这样它们就不会被简化。这样一来我们在简化步骤中只要简化到只剩预着色节点、传送有关节点和高度数节点的图就可以了。
这一般不会引起问题，因为这些预着色的变量通常有着很短的生命周期。
